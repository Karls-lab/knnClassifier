{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
      "      dtype='object')\n",
      "0      2.3\n",
      "1      1.5\n",
      "2      2.6\n",
      "3      3.5\n",
      "4      1.4\n",
      "      ... \n",
      "298    1.2\n",
      "299    3.4\n",
      "300    1.2\n",
      "301    0.0\n",
      "302    0.0\n",
      "Name: oldpeak, Length: 303, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('cleveland.csv')\n",
    "print(df.columns)\n",
    "\n",
    "\"\"\" Convert num into a 0 or 1\"\"\"\n",
    "df['num'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(df['oldpeak'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each continuous value, place the values into a bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thal 0.208\n",
      "cp 0.205\n",
      "ca 0.181\n",
      "oldpeak_bin 0.163\n",
      "thalach_bin 0.149\n",
      "exang 0.139\n",
      "slope 0.112\n",
      "age_bin 0.073\n",
      "sex 0.057\n",
      "restecg 0.024\n",
      "trestbps_bin 0.023\n",
      "chol_bin 0.02\n",
      "fbs 0.0\n"
     ]
    }
   ],
   "source": [
    "# Perform information gain on each feature\n",
    "import math \n",
    "\n",
    "def entropy(class_probs):\n",
    "    return -sum(p * math.log2(p) for p in class_probs if p != 0)\n",
    "\n",
    "def information_gain(data, feature, target):\n",
    "    class_probs = data[target].value_counts(normalize=True)\n",
    "    entropy_before = round(entropy(class_probs), 3)\n",
    "    \n",
    "    values = data[feature].unique()\n",
    "    weighted_entropy_after = 0\n",
    "    \n",
    "    for value in values:\n",
    "        subset = data[data[feature] == value]\n",
    "        prob_value = len(subset) / len(data)\n",
    "        class_probs_subset = subset[target].value_counts(normalize=True)\n",
    "        entropy_after = entropy(class_probs_subset)\n",
    "        weighted_entropy_after += prob_value * entropy_after\n",
    "    \n",
    "    weighted_entropy_after = round(weighted_entropy_after, 3)\n",
    "    information_gain = round(entropy_before - weighted_entropy_after, 3)\n",
    "    return information_gain\n",
    "\n",
    "# Used to calculate information gain on continuous feature\n",
    "def discretize_feature(data, feature, num_bins=10):\n",
    "    # Use pandas' cut function to bin the continuous feature\n",
    "    new_feature = feature + '_bin'\n",
    "    data[new_feature] = pd.cut(data[feature], bins=num_bins)\n",
    "    return new_feature, data\n",
    "\n",
    "\n",
    "# Caluclate information gain for each categorial\n",
    "discrete_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "features_inf0_gain = {}\n",
    "for feature in df.columns:\n",
    "    if feature == 'num':\n",
    "        continue\n",
    "    if feature in discrete_features:\n",
    "        new_feature, disFeature = discretize_feature(df, feature)\n",
    "        ig = information_gain(disFeature, new_feature, 'num')\n",
    "        features_inf0_gain[new_feature] = ig\n",
    "    else:\n",
    "        ig = information_gain(df, feature, 'num')\n",
    "        features_inf0_gain[feature] = ig\n",
    "\n",
    "features_inf0_gain = {k: v for k, v in sorted(features_inf0_gain.items(), key=lambda item: item[1], reverse=True)}\n",
    "for k, v in features_inf0_gain.items():\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up data for Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('cleveland.csv')\n",
    "df['num'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['num'] = df['num'].astype('category')\n",
    "\n",
    "selectedFeatures = ['thal', 'cp', 'ca', 'oldpeak', 'thalach', 'exang']\n",
    "categoricalFeatures = ['cp', 'ca', 'thal', 'exang']\n",
    "continuousFeatures = ['thalach', 'oldpeak']\n",
    "df = df[selectedFeatures + ['num']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare categorical features\n",
    "\"\"\"\n",
    "\n",
    "# convert categorial features into 'str' type\n",
    "for feature in categoricalFeatures:\n",
    "    df[feature] = df[feature].astype('str')\n",
    "\n",
    "# Define mappings for each categorical feature\n",
    "feature_mappings = {\n",
    "    'cp': {'1.0': 0, '2.0': 0.33, '3.0': 0.67, '4.0': 1},\n",
    "    'thal': {'3.0': 0, '6.0': 0.5, '7.0': 1},\n",
    "    'ca': {'0.0': 0, '1.0': 0.33, '2.0': 0.67, '3.0': 1},\n",
    "    'exang': {'0.0': 0, '1.0': 1}\n",
    "    # 'slope': {'1.0': 0, '2.0': 0.5, '3.0': 1}\n",
    "}\n",
    "\n",
    "# Map the categorical variables to 0-1 and remove rows with '?'\n",
    "for feature, valid_values in feature_mappings.items():\n",
    "    df = df[df[feature] != '?']\n",
    "    df[feature] = df[feature].map(valid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting thalach to numeric\n",
      "Converting oldpeak to numeric\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Clean up Continuous Features\n",
    "\"\"\"\n",
    "\n",
    "# remove rows that are not numeric\n",
    "for feature in continuousFeatures:\n",
    "    print(f\"Converting {feature} to numeric\")\n",
    "    df = df[pd.to_numeric(df[feature], errors='coerce').notna()]\n",
    "\n",
    "# Z-score normalization\n",
    "for feature in continuousFeatures:\n",
    "    mean = df[feature].mean()\n",
    "    std = df[feature].std()\n",
    "    df[feature] = (df[feature] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[selectedFeatures] = df[selectedFeatures].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 297 entries, 0 to 301\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   thal     297 non-null    float16 \n",
      " 1   cp       297 non-null    float16 \n",
      " 2   ca       297 non-null    float16 \n",
      " 3   oldpeak  297 non-null    float16 \n",
      " 4   thalach  297 non-null    float16 \n",
      " 5   exang    297 non-null    float16 \n",
      " 6   num      297 non-null    category\n",
      "dtypes: category(1), float16(6)\n",
      "memory usage: 6.2 KB\n",
      "None\n",
      "\n",
      "\n",
      " DF HEAD\n",
      "   thal        cp        ca   oldpeak   thalach  exang num\n",
      "0   0.5  0.000000  0.000000  1.067383  0.017471    0.0   0\n",
      "1   0.0  1.000000  1.000000  0.381104 -1.813477    1.0   1\n",
      "2   1.0  1.000000  0.669922  1.324219 -0.897949    1.0   1\n",
      "3   0.0  0.669922  0.000000  2.095703  1.629883    0.0   0\n",
      "4   0.0  0.330078  0.000000  0.295410  0.976562    0.0   0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Now lets save the data \"\"\"\n",
    "print(df.info())\n",
    "df.to_csv('cleveland_cleaned.csv', index=False)\n",
    "\n",
    "print(f\"\\n\\n DF HEAD\")\n",
    "print(df.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
